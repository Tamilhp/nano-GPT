{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b81f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034cf2c5",
   "metadata": {},
   "source": [
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e264e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-17 13:18:36--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt.4’\n",
      "\n",
      "input.txt.4         100%[===================>]   1.06M  --.-KB/s    in 0.01s   \n",
      "\n",
      "2023-07-17 13:18:36 (96.4 MB/s) - ‘input.txt.4’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f557df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\", 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3a637f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the tiny shakesphere dataset 1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"length of the tiny shakesphere dataset\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "974a4daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz \n",
      "Vocabulary_size 65\n"
     ]
    }
   ],
   "source": [
    "# Checking the vocabulary size\n",
    "\n",
    "vocab = sorted(list(set(text)))\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocabulary: \", ''.join(vocab), \"\\nVocabulary_size\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cdc4e5",
   "metadata": {},
   "source": [
    "### Tokenize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989ac7df",
   "metadata": {},
   "source": [
    "Tokenizing the data actually means that encoding our input data which are in text into integers(numbers) which the computer can understand\n",
    "\n",
    "- Google uses **Sentence-piece** tokenizer to encode the input data\n",
    "- OpenAI uses **tiktoken** tokenizer to encode the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a56d630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from charaters to integers\n",
    "stoi = {ch:i for i,ch in enumerate(vocab)}\n",
    "itos = {i:ch for i,ch in enumerate(vocab)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join(itos[c] for c in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b378d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "encoded = encode(\"hii there\")\n",
    "print(encoded)\n",
    "decoded = decode(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca6e167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) <built-in method type of Tensor object at 0x7fb6caf331a0>\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# Encode the entire dataset and store it in tensor\n",
    "import torch\n",
    "\n",
    "encoded_data = encode(text)\n",
    "data = torch.tensor(encoded_data, dtype=torch.long)\n",
    "print(data.shape, data.type)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77ac2491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train data and val data\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cf1903",
   "metadata": {},
   "source": [
    "### Data Loader: Batches of chunk of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d105c546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize and understand the input and output\n",
    "\n",
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c0050a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the input is tensor([18]) the output is 47\n",
      "When the input is tensor([18, 47]) the output is 56\n",
      "When the input is tensor([18, 47, 56]) the output is 57\n",
      "When the input is tensor([18, 47, 56, 57]) the output is 58\n",
      "When the input is tensor([18, 47, 56, 57, 58]) the output is 1\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1]) the output is 15\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1, 15]) the output is 47\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the output is 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"When the input is {context} the output is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "007168bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb7bcb81e30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  \n",
      " torch.Size([4, 8]) \n",
      " tensor([[57, 11,  0, 18, 53, 56,  1,  5],\n",
      "        [40, 43,  1, 61, 43, 50, 50,  1],\n",
      "        [52, 43, 56, 39, 50,  8,  0, 31],\n",
      "        [46, 58,  1, 53, 44,  1, 57, 59]])\n",
      "targets: \n",
      " torch.Size([4, 8]) \n",
      " tensor([[11,  0, 18, 53, 56,  1,  5, 58],\n",
      "        [43,  1, 61, 43, 50, 50,  1, 39],\n",
      "        [43, 56, 39, 50,  8,  0, 31, 46],\n",
      "        [58,  1, 53, 44,  1, 57, 59, 41]])\n",
      "When the input is [57] the output is 11\n",
      "When the input is [57, 11] the output is 0\n",
      "When the input is [57, 11, 0] the output is 18\n",
      "When the input is [57, 11, 0, 18] the output is 53\n",
      "When the input is [57, 11, 0, 18, 53] the output is 56\n",
      "When the input is [57, 11, 0, 18, 53, 56] the output is 1\n",
      "When the input is [57, 11, 0, 18, 53, 56, 1] the output is 5\n",
      "When the input is [57, 11, 0, 18, 53, 56, 1, 5] the output is 58\n",
      "When the input is [40] the output is 43\n",
      "When the input is [40, 43] the output is 1\n",
      "When the input is [40, 43, 1] the output is 61\n",
      "When the input is [40, 43, 1, 61] the output is 43\n",
      "When the input is [40, 43, 1, 61, 43] the output is 50\n",
      "When the input is [40, 43, 1, 61, 43, 50] the output is 50\n",
      "When the input is [40, 43, 1, 61, 43, 50, 50] the output is 1\n",
      "When the input is [40, 43, 1, 61, 43, 50, 50, 1] the output is 39\n",
      "When the input is [52] the output is 43\n",
      "When the input is [52, 43] the output is 56\n",
      "When the input is [52, 43, 56] the output is 39\n",
      "When the input is [52, 43, 56, 39] the output is 50\n",
      "When the input is [52, 43, 56, 39, 50] the output is 8\n",
      "When the input is [52, 43, 56, 39, 50, 8] the output is 0\n",
      "When the input is [52, 43, 56, 39, 50, 8, 0] the output is 31\n",
      "When the input is [52, 43, 56, 39, 50, 8, 0, 31] the output is 46\n",
      "When the input is [46] the output is 58\n",
      "When the input is [46, 58] the output is 1\n",
      "When the input is [46, 58, 1] the output is 53\n",
      "When the input is [46, 58, 1, 53] the output is 44\n",
      "When the input is [46, 58, 1, 53, 44] the output is 1\n",
      "When the input is [46, 58, 1, 53, 44, 1] the output is 57\n",
      "When the input is [46, 58, 1, 53, 44, 1, 57] the output is 59\n",
      "When the input is [46, 58, 1, 53, 44, 1, 57, 59] the output is 41\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1729)\n",
    "batch_size = 4 # How many sequence will we process in parallel?\n",
    "block_size = 8 # What is the maximum context length for prediction?\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split==\"train\" else val_data\n",
    "    ix = torch.randint(len(data)-block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs: \",\"\\n\", xb.shape,\"\\n\", xb)\n",
    "print(\"targets:\", \"\\n\", yb.shape, \"\\n\", yb)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"When the input is {context.tolist()} the output is {target}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab50f97",
   "metadata": {},
   "source": [
    "### Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e0a8004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb7bcb81e30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(65, 65)\n",
      "torch.Size([32, 65])\n",
      "tensor(4.5080, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "'dsygtny:u&UeOdUoE!SZDoz ,r;XduqxqRfl$hAAPGQYJK'AjoyRBxu&S.Hf$ehumv;vkSfInJ.HnUeOkssEZ&&noAAA.iGpu&O\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1729)\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # Each token directly reads off the logits from the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        print(self.token_embedding_table)\n",
    "        \n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) #(B, T, C)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            # Calculate the cross entropy loss\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # (B, C)\n",
    "            # Apply softmax to get the probabilities\n",
    "            probs = F.softmax(logits, dim=-1) #(B, C)\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) #(B, 1)\n",
    "            # append sampled index to the urunning sequence\n",
    "            idx = torch.cat((idx, idx_next), dim =1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ae1db9",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e91a0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e98c31da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6193814277648926\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    \n",
    "    # Sample a batch of data\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    \n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    # Zeroing out all the gradients from the previous step\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    # Getting the parameters from all the gradients\n",
    "    loss.backward()\n",
    "    # Use the gradients to update the parameters\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11d41ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCHolar'd tofowee\n",
      "waineerece f fan, me n thothilererndanstsheserd tllly vitchin:\n",
      "YBEGHNon\n",
      "CHerd wed s s?\n",
      "HUSancoug PRCI Cl and d t;\n",
      "LAs courte\n",
      "ALAnpofamos ptaistaur'aurit honest d.\n",
      "Dof ke c isher, s d ithe sld wiren irk the t:\n",
      "L:\n",
      "Thor halleishene ome anoun\n",
      "y wites al s m,\n",
      "ARI m,\n",
      "\n",
      "INTevenoseered pa s, Ano--s th\n",
      "AMES:\n",
      "\n",
      "Cotheabre athb g, f:\n",
      "May wis acly she wnd, hrey y antin aveng, t n:\n",
      "\n",
      "Anind he;\n",
      "Yewoufsly,\n",
      "Mas athereyofly.\n",
      "d.\n",
      "Tfave bausem:\n",
      "M:\n",
      "Bre I an thonshad che hand w, ANRD be, sieayind bon a m bugepus Hedopeiss,\n",
      "ARD: trt, cten the busn.\n",
      "\n",
      "Ses:\n",
      "\n",
      "PO: wir t t.\n",
      "Her ou has tir'rqusthe sous as l.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=600)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7fee30",
   "metadata": {},
   "source": [
    "### Self attention block\n",
    "\n",
    "#### The mathematical trick in self-attention block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0f164c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb7bcb81e30>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Toy example\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "B, T, C = 4, 8, 2 # Batch, Time, Channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b418e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t, C)\n",
    "        xbow[b, t] = torch.mean(xprev, 0) # Doubt on what 0 does here??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afce1642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 2: Vectorizing the above operation\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei/ torch.sum(wei, 1, keepdim = True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) = (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d3b0f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 3:\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.ones(T, T)\n",
    "wei = tril.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64837653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb7bcb81e30>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "---\n",
      "b=\n",
      "tensor([[1., 0.],\n",
      "        [7., 7.],\n",
      "        [9., 0.]])\n",
      "---\n",
      "c=\n",
      "tensor([[1.0000, 0.0000],\n",
      "        [4.0000, 3.5000],\n",
      "        [5.6667, 2.3333]])\n"
     ]
    }
   ],
   "source": [
    "# The trick in self-attention: matrix multiply as weighted aggregation\n",
    "torch.manual_seed(1729)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3,2)).float()\n",
    "c = a @ b\n",
    "print(\"a=\")\n",
    "print(a)\n",
    "print(\"---\")\n",
    "print(\"b=\")\n",
    "print(b)\n",
    "print(\"---\")\n",
    "print(\"c=\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7542134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb7bcb81e30>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: Self-attention\n",
    "torch.manual_seed(1729)\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "# let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)\n",
    "q = key(x)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec32a7dc",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode vectors\n",
    "- Each example across batch dimension is of course processed completely independently and \"never talk\" to each other\n",
    "- In an \"encoder\" attention block, just delete the single line that does masking with tril, allowing all tokens to communicate with each other. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in auto-regressive settings(GPT-2, GPT-3), like language modeling.\n",
    "- \"Self-attention\" means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source(e.g. an encoder module)\n",
    "- \"Scaled attention\" additionally divides wei by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and softmax will stay diffuse and not saturate too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12a3f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "wei = k @ q.transpose(-2, -1) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f90be6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9954)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95e64f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0377)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a93461ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1652)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7bbbcca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1904, 0.1410, 0.1276, 0.2570, 0.2840])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, -0.3, 0.4, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c5276d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bfaaf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
